{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import explained_variance_score, \\\n",
    "    mean_absolute_error, \\\n",
    "    median_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxtempm</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>70.611388</td>\n",
       "      <td>7.342503</td>\n",
       "      <td>13.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>56.513054</td>\n",
       "      <td>6.764928</td>\n",
       "      <td>18.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtempm</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>63.562254</td>\n",
       "      <td>6.390625</td>\n",
       "      <td>16.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>63.50</td>\n",
       "      <td>68.00</td>\n",
       "      <td>89.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtempm_1</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>63.626542</td>\n",
       "      <td>9.885656</td>\n",
       "      <td>43.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>63.50</td>\n",
       "      <td>68.00</td>\n",
       "      <td>996.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtempm_2</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>63.627132</td>\n",
       "      <td>9.941455</td>\n",
       "      <td>43.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>63.50</td>\n",
       "      <td>68.00</td>\n",
       "      <td>1005.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanhdd_3</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>3.437200</td>\n",
       "      <td>9.093399</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1002.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanhdd_1</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>3.372507</td>\n",
       "      <td>4.154159</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanhdd_2</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>3.374606</td>\n",
       "      <td>4.168600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meancdd_1</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>1.940075</td>\n",
       "      <td>3.243770</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meancdd_2</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>3.222247</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>24.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meancdd_3</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>3.222247</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>24.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minPrecipitationWaterEquiv</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>0.033664</td>\n",
       "      <td>0.179820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxPrecipitationWaterEquiv</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>0.033664</td>\n",
       "      <td>0.179820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanPrecipitationWaterEquiv</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>0.033664</td>\n",
       "      <td>0.179820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minSnowfall</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxSnowfall</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanSnowfall</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow/IceDepth_1</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow/IceDepth_2</th>\n",
       "      <td>15244.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow/IceDepth_3</th>\n",
       "      <td>15243.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewpt</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>7.041136</td>\n",
       "      <td>11.449679</td>\n",
       "      <td>-94.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewpt</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>15.802454</td>\n",
       "      <td>7.195610</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewpt</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>11.561540</td>\n",
       "      <td>8.648016</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressure</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1005.706403</td>\n",
       "      <td>7.040041</td>\n",
       "      <td>992.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1005.00</td>\n",
       "      <td>1012.00</td>\n",
       "      <td>1020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressure</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1012.617964</td>\n",
       "      <td>6.466685</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>1013.00</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1026.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressure</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1009.859609</td>\n",
       "      <td>6.406514</td>\n",
       "      <td>997.63</td>\n",
       "      <td>1004.09</td>\n",
       "      <td>1009.70</td>\n",
       "      <td>1015.54</td>\n",
       "      <td>1023.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>22.161134</td>\n",
       "      <td>19.055102</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>89.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>66.993505</td>\n",
       "      <td>21.674154</td>\n",
       "      <td>15.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanhumidity</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>66.993505</td>\n",
       "      <td>21.674154</td>\n",
       "      <td>15.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterlevel_1</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterlevel_2</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterlevel_3</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minWaterlevel_1</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minWaterlevel_2</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minWaterlevel_3</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxWaterlevel_1</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxWaterlevel_2</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxWaterlevel_3</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterlevel</th>\n",
       "      <td>15242.0</td>\n",
       "      <td>1.714297</td>\n",
       "      <td>0.779632</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.69</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count         mean        std     min      25%  \\\n",
       "maxtempm                     15244.0    70.611388   7.342503   13.00    65.00   \n",
       "mintempm                     15244.0    56.513054   6.764928   18.00    52.00   \n",
       "avgtempm                     15244.0    63.562254   6.390625   16.00    59.00   \n",
       "avgtempm_1                   15244.0    63.626542   9.885656   43.00    59.00   \n",
       "avgtempm_2                   15244.0    63.627132   9.941455   43.00    59.00   \n",
       "meanhdd_3                    15244.0     3.437200   9.093399    0.00     0.00   \n",
       "meanhdd_1                    15244.0     3.372507   4.154159    0.00     0.00   \n",
       "meanhdd_2                    15244.0     3.374606   4.168600    0.00     0.00   \n",
       "meancdd_1                    15244.0     1.940075   3.243770    0.00     0.00   \n",
       "meancdd_2                    15244.0     1.937015   3.222247    0.00     0.00   \n",
       "meancdd_3                    15244.0     1.937015   3.222247    0.00     0.00   \n",
       "minPrecipitationWaterEquiv   15244.0     0.033664   0.179820    0.00     0.00   \n",
       "maxPrecipitationWaterEquiv   15244.0     0.033664   0.179820    0.00     0.00   \n",
       "meanPrecipitationWaterEquiv  15244.0     0.033664   0.179820    0.00     0.00   \n",
       "minSnowfall                  15242.0     0.000089   0.010935    0.00     0.00   \n",
       "maxSnowfall                  15242.0     0.000089   0.010935    0.00     0.00   \n",
       "meanSnowfall                 15242.0     0.000089   0.010935    0.00     0.00   \n",
       "Snow/IceDepth_1              15244.0     0.000089   0.010934    0.00     0.00   \n",
       "Snow/IceDepth_2              15244.0     0.000089   0.010934    0.00     0.00   \n",
       "Snow/IceDepth_3              15243.0     0.000000   0.000000    0.00     0.00   \n",
       "mindewpt                     15242.0     7.041136  11.449679  -94.00    -1.00   \n",
       "maxdewpt                     15242.0    15.802454   7.195610    0.00    10.00   \n",
       "meandewpt                    15242.0    11.561540   8.648016  -10.00     5.00   \n",
       "minpressure                  15242.0  1005.706403   7.040041  992.00  1000.00   \n",
       "maxpressure                  15242.0  1012.617964   6.466685  999.00  1007.00   \n",
       "meanpressure                 15242.0  1009.859609   6.406514  997.63  1004.09   \n",
       "minhumidity                  15242.0    22.161134  19.055102    4.00     9.00   \n",
       "maxhumidity                  15242.0    66.993505  21.674154   15.00    51.00   \n",
       "meanhumidity                 15242.0    66.993505  21.674154   15.00    51.00   \n",
       "Waterlevel_1                 15242.0     1.714297   0.779632    1.25     1.29   \n",
       "Waterlevel_2                 15242.0     1.714297   0.779632    1.25     1.29   \n",
       "Waterlevel_3                 15242.0     1.714297   0.779632    1.25     1.29   \n",
       "minWaterlevel_1              15242.0     1.714297   0.779632    1.25     1.29   \n",
       "minWaterlevel_2              15242.0     1.714297   0.779632    1.25     1.29   \n",
       "minWaterlevel_3              15242.0     1.714297   0.779632    1.25     1.29   \n",
       "maxWaterlevel_1              15242.0     1.714297   0.779632    1.25     1.29   \n",
       "maxWaterlevel_2              15242.0     1.714297   0.779632    1.25     1.29   \n",
       "maxWaterlevel_3              15242.0     1.714297   0.779632    1.25     1.29   \n",
       "Waterlevel                   15242.0     1.714297   0.779632    1.25     1.29   \n",
       "\n",
       "                                 50%      75%      max  \n",
       "maxtempm                       70.00    75.00   106.00  \n",
       "mintempm                       57.00    62.00    77.00  \n",
       "avgtempm                       63.50    68.00    89.50  \n",
       "avgtempm_1                     63.50    68.00   996.00  \n",
       "avgtempm_2                     63.50    68.00  1005.00  \n",
       "meanhdd_3                       1.50     6.00  1002.18  \n",
       "meanhdd_1                       1.50     6.00    22.00  \n",
       "meanhdd_2                       1.50     6.00    48.00  \n",
       "meancdd_1                       0.00     3.00    48.00  \n",
       "meancdd_2                       0.00     3.00    24.50  \n",
       "meancdd_3                       0.00     3.00    24.50  \n",
       "minPrecipitationWaterEquiv      0.00     0.00     4.53  \n",
       "maxPrecipitationWaterEquiv      0.00     0.00     4.53  \n",
       "meanPrecipitationWaterEquiv     0.00     0.00     4.53  \n",
       "minSnowfall                     0.00     0.00     1.35  \n",
       "maxSnowfall                     0.00     0.00     1.35  \n",
       "meanSnowfall                    0.00     0.00     1.35  \n",
       "Snow/IceDepth_1                 0.00     0.00     1.35  \n",
       "Snow/IceDepth_2                 0.00     0.00     1.35  \n",
       "Snow/IceDepth_3                 0.00     0.00     0.00  \n",
       "mindewpt                        5.00    17.00    25.00  \n",
       "maxdewpt                       14.00    23.00    29.00  \n",
       "meandewpt                       9.00    20.00    26.00  \n",
       "minpressure                  1005.00  1012.00  1020.00  \n",
       "maxpressure                  1013.00  1018.00  1026.00  \n",
       "meanpressure                 1009.70  1015.54  1023.43  \n",
       "minhumidity                    14.00    31.00    89.00  \n",
       "maxhumidity                    66.00    87.00   100.00  \n",
       "meanhumidity                   66.00    87.00   100.00  \n",
       "Waterlevel_1                    1.34     1.69     4.35  \n",
       "Waterlevel_2                    1.34     1.69     4.35  \n",
       "Waterlevel_3                    1.34     1.69     4.35  \n",
       "minWaterlevel_1                 1.34     1.69     4.35  \n",
       "minWaterlevel_2                 1.34     1.69     4.35  \n",
       "minWaterlevel_3                 1.34     1.69     4.35  \n",
       "maxWaterlevel_1                 1.34     1.69     4.35  \n",
       "maxWaterlevel_2                 1.34     1.69     4.35  \n",
       "maxWaterlevel_3                 1.34     1.69     4.35  \n",
       "Waterlevel                      1.34     1.69     4.35  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_memory=False\n",
    "df = pd.read_csv('LA.csv').set_index('date')\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15244 entries, 02/11/78 to 11/05/19\n",
      "Data columns (total 39 columns):\n",
      "maxtempm                       15244 non-null int64\n",
      "mintempm                       15244 non-null int64\n",
      "avgtempm                       15244 non-null float64\n",
      "avgtempm_1                     15244 non-null float64\n",
      "avgtempm_2                     15244 non-null float64\n",
      "meanhdd_3                      15244 non-null float64\n",
      "meanhdd_1                      15244 non-null float64\n",
      "meanhdd_2                      15244 non-null float64\n",
      "meancdd_1                      15244 non-null float64\n",
      "meancdd_2                      15244 non-null float64\n",
      "meancdd_3                      15244 non-null float64\n",
      "minPrecipitationWaterEquiv     15244 non-null float64\n",
      "maxPrecipitationWaterEquiv     15244 non-null float64\n",
      "meanPrecipitationWaterEquiv    15244 non-null float64\n",
      "minSnowfall                    15242 non-null float64\n",
      "maxSnowfall                    15242 non-null float64\n",
      "meanSnowfall                   15242 non-null float64\n",
      "Snow/IceDepth_1                15244 non-null float64\n",
      "Snow/IceDepth_2                15244 non-null float64\n",
      "Snow/IceDepth_3                15243 non-null float64\n",
      "mindewpt                       15242 non-null float64\n",
      "maxdewpt                       15242 non-null float64\n",
      "meandewpt                      15242 non-null float64\n",
      "minpressure                    15242 non-null float64\n",
      "maxpressure                    15242 non-null float64\n",
      "meanpressure                   15242 non-null float64\n",
      "minhumidity                    15242 non-null float64\n",
      "maxhumidity                    15242 non-null float64\n",
      "meanhumidity                   15242 non-null float64\n",
      "Waterlevel_1                   15242 non-null float64\n",
      "Waterlevel_2                   15242 non-null float64\n",
      "Waterlevel_3                   15242 non-null float64\n",
      "minWaterlevel_1                15242 non-null float64\n",
      "minWaterlevel_2                15242 non-null float64\n",
      "minWaterlevel_3                15242 non-null float64\n",
      "maxWaterlevel_1                15242 non-null float64\n",
      "maxWaterlevel_2                15242 non-null float64\n",
      "maxWaterlevel_3                15242 non-null float64\n",
      "Waterlevel                     15242 non-null float64\n",
      "dtypes: float64(37), int64(2)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['mintempm', 'maxtempm'], axis=1)\n",
    "\n",
    "X = df[[col for col in df.columns if col != 'Waterlevel']]\n",
    "\n",
    "y = df['Waterlevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   12195, Training features   36\n",
      "Validation instances 1525, Validation features 36\n",
      "Testing instances    1524, Testing features    36\n"
     ]
    }
   ],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=23)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n",
    "print(\"Training instances   {}, Training features   {}\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"Validation instances {}, Validation features {}\".format(X_val.shape[0], X_val.shape[1]))\n",
    "print(\"Testing instances    {}, Testing features    {}\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(col) for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tf_wx_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a49b6ae90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,\n",
    "                                      hidden_units=[20, 20],\n",
    "                                      model_dir='tf_wx_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wx_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=20): # 260 is used as we have approx 570 dataset for training\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(x=X,\n",
    "                                               y=y,\n",
    "                                               num_epochs=num_epochs,\n",
    "                                               shuffle=shuffle,\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-580\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 580 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.263857, step = 580\n",
      "INFO:tensorflow:Saving checkpoints for 600 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4574835.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:36\n",
      "INFO:tensorflow:Saving dict for global step 600: average_loss = 1.2520969, global_step = 600, label/mean = 1.5065, loss = 1.2520969, prediction/mean = 1.2711395\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: tf_wx_model/model.ckpt-600\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:38\n",
      "INFO:tensorflow:Saving dict for global step 600: average_loss = 1.4931039, global_step = 600, label/mean = 1.7300062, loss = 1.4930407, prediction/mean = 1.638726\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: tf_wx_model/model.ckpt-600\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 600 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.8152813, step = 600\n",
      "INFO:tensorflow:Saving checkpoints for 620 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4695115.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-620\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:43\n",
      "INFO:tensorflow:Saving dict for global step 620: average_loss = 1.2395617, global_step = 620, label/mean = 1.5065, loss = 1.2395617, prediction/mean = 1.2369467\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 620: tf_wx_model/model.ckpt-620\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-620\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:45\n",
      "INFO:tensorflow:Saving dict for global step 620: average_loss = 1.4625306, global_step = 620, label/mean = 1.7300062, loss = 1.4627535, prediction/mean = 1.5992316\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 620: tf_wx_model/model.ckpt-620\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-620\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 620 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.8196808, step = 620\n",
      "INFO:tensorflow:Saving checkpoints for 640 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8605301.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:49\n",
      "INFO:tensorflow:Saving dict for global step 640: average_loss = 1.2940446, global_step = 640, label/mean = 1.5065, loss = 1.2940446, prediction/mean = 1.1208899\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 640: tf_wx_model/model.ckpt-640\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:51\n",
      "INFO:tensorflow:Saving dict for global step 640: average_loss = 1.4745132, global_step = 640, label/mean = 1.7300062, loss = 1.4754035, prediction/mean = 1.4777219\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 640: tf_wx_model/model.ckpt-640\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 640 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.2690227, step = 640\n",
      "INFO:tensorflow:Saving checkpoints for 660 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.3470242.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:55\n",
      "INFO:tensorflow:Saving dict for global step 660: average_loss = 1.1522964, global_step = 660, label/mean = 1.5065, loss = 1.1522964, prediction/mean = 1.3329675\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 660: tf_wx_model/model.ckpt-660\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:29:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:29:58\n",
      "INFO:tensorflow:Saving dict for global step 660: average_loss = 1.3735944, global_step = 660, label/mean = 1.7300062, loss = 1.3735821, prediction/mean = 1.6845922\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 660: tf_wx_model/model.ckpt-660\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-660\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 660 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4047999, step = 660\n",
      "INFO:tensorflow:Saving checkpoints for 680 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.4001172.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:30:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-680\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:30:03\n",
      "INFO:tensorflow:Saving dict for global step 680: average_loss = 1.2106607, global_step = 680, label/mean = 1.5065, loss = 1.2106607, prediction/mean = 1.8435307\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 680: tf_wx_model/model.ckpt-680\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:30:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-680\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:30:05\n",
      "INFO:tensorflow:Saving dict for global step 680: average_loss = 1.5464927, global_step = 680, label/mean = 1.7300062, loss = 1.5439773, prediction/mean = 2.1907783\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 680: tf_wx_model/model.ckpt-680\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-680\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 680 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.0027578, step = 680\n",
      "INFO:tensorflow:Saving checkpoints for 700 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2423158.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:30:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:30:11\n",
      "INFO:tensorflow:Saving dict for global step 700: average_loss = 1.111985, global_step = 700, label/mean = 1.5065, loss = 1.111985, prediction/mean = 1.3455231\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 700: tf_wx_model/model.ckpt-700\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-15T15:30:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-15-15:30:14\n",
      "INFO:tensorflow:Saving dict for global step 700: average_loss = 1.3079932, global_step = 700, label/mean = 1.7300062, loss = 1.3081169, prediction/mean = 1.6871508\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 700: tf_wx_model/model.ckpt-700\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 700 into tf_wx_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3244495, step = 700\n",
      "ERROR:tensorflow:Model diverged with loss = NaN.\n"
     ]
    },
    {
     "ename": "NanLossDuringTrainingError",
     "evalue": "NaN loss during training.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNanLossDuringTrainingError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-11754f383b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSTEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwx_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     evaluation = regressor.evaluate(input_fn=wx_input_fn(X_val, y_val,\n\u001b[1;32m      6\u001b[0m                                                          \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1193\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1491\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1260\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         logging.info(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1424\u001b[0m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m               run_metadata=run_metadata))\n\u001b[0m\u001b[1;32m   1427\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mafter_run\u001b[0;34m(self, run_context, run_values)\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fail_on_nan_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailure_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNanLossDuringTrainingError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailure_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNanLossDuringTrainingError\u001b[0m: NaN loss during training."
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "STEPS = 20\n",
    "for i in range(40):\n",
    "    regressor.train(input_fn=wx_input_fn(X_train, y=y_train), steps=STEPS)\n",
    "    evaluation = regressor.evaluate(input_fn=wx_input_fn(X_val, y_val,\n",
    "                                                         num_epochs=1,\n",
    "                                                         shuffle=False),\n",
    "                                    steps=1)\n",
    "    evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                               y_val,\n",
    "                                                               num_epochs=1,\n",
    "                                                               shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_loss': 60.79368,\n",
       " 'label/mean': 1.7300062,\n",
       " 'loss': 60.86932,\n",
       " 'prediction/mean': 6.9116273,\n",
       " 'global_step': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz0AAAJNCAYAAAAbPRsAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5Rd110n+O8PSSFFEqiEKBlLDthpjJo0BotWp9PjgYYEkHk0EYZA0jw84BlDDzCBsAQWM8NADyw7S81jepoOmLxMQ17jCDmTBISxEwJMEyIjJ8oDdZyQDi6F2JAIku4aIit7/qhTdlmpUlVZ99a9tevzWUvr3rPvuef+auu4dL/e++xTrbUAAAD06rMmXQAAAMA4CT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRt+6QLWIsnP/nJ7bLLLpt0GQAAwJS6++67/7q1tnO51zZF6Lnsssty/PjxSZcBAABMqar6zyu9ZnobAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAurZ90gVsFkdPzOXwsVM5fWY+u2ZncnD/nhzYu3vSZQEAAKsQetbg6Im5HDpyMvNnzyVJ5s7M59CRk0ki+AAAwJQzvW0NDh879VDgWTR/9lwOHzs1oYoAAIC1EnrW4PSZ+XW1AwAA00PoWYNdszPragcAAKaH0LMGB/fvycyObY9om9mxLQf375lQRQAAwFqNNfRU1WxV3VZVf15V76uqf1ZVT6qqO6rq/cPjE8dZwygc2Ls7N117ZXbPzqSS7J6dyU3XXmkRAwAA2ASqtTa+g1fdmuQPW2svrarHJPmcJD+V5GOttZur6sYkT2yt/eSFjrNv3752/PjxsdUJAABsblV1d2tt33KvjW2kp6o+N8lXJXlZkrTWPtVaO5PkuUluHXa7NcmBcdUAAAAwzultT0/yQJJXVNWJqnppVT0uyVNbax9JkuHxKWOsAQAA2OLGGXq2J/mKJC9pre1N8l+S3LjWN1fVDVV1vKqOP/DAA+OqEQAA6Nw4Q899Se5rrb192L4tCyHoo1V1SZIMj/cv9+bW2i2ttX2ttX07d+4cY5kAAEDPxhZ6Wmt/leQvq2pxXefnJHlvkjckuW5ouy7J7eOqAQAAYPuYj/8jSX5rWLntg0m+LwtB63VVdX2SDyd53phrAAAAtrCxhp7W2j1Jlls27jnj/FwAAIBFY705KQAAwKQJPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0LXt4zx4VX0oySeSnEvyYGttX1U9Kclrk1yW5ENJvqO19vFx1gEAAGxdGzHS8zWttataa/uG7RuT3NlauyLJncM2AADAWExiettzk9w6PL81yYEJ1AAAAGwR4w49LcnvVdXdVXXD0PbU1tpHkmR4fMqYawAAALawsV7Tk+Tq1trpqnpKkjuq6s/X+sYhJN2QJF/wBV8wrvoAAIDOjXWkp7V2eni8P8lvJ3lmko9W1SVJMjzev8J7b2mt7Wut7du5c+c4ywQAADo2ttBTVY+rqicsPk/y9UneneQNSa4bdrsuye3jqgEAAGCc09uemuS3q2rxc17VWvvdqnpHktdV1fVJPpzkeWOsAQAA2OLGFnpaax9M8uXLtP9NkueM63MBAACWmsSS1QAAABtG6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0be+ipqm1VdaKq3jhsX15Vb6+q91fVa6vqMeOuAQAA2Lo2YqTnhUnet2T7xUl+qbV2RZKPJ7l+A2oAAAC2qLGGnqq6NMk3JXnpsF1Jnp3ktmGXW5McGGcNAADA1jbukZ5fTvITST49bH9+kjOttQeH7fuS7B5zDQAAwBY2ttBTVd+c5P7W2t1Lm5fZta3w/huq6nhVHX/ggQfGUiMAANC/cY70XJ3kW6rqQ0lek4Vpbb+cZLaqtg/7XJrk9HJvbq3d0lrb11rbt3PnzjGWCQAA9Gxsoae1dqi1dmlr7bIkz09yV2vtu5K8Jcm3D7tdl+T2cdUAAAAwifv0/GSSF1XVvVm4xudlE6gBAADYIravvsvFa629Nclbh+cfTPLMjfhcAACASYz0AAAAbBihBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOja9tV2qKpLkzw/yVcm2ZVkPsm7k7wpye+01j491goBAAAuwgVDT1W9IsnuJG9M8uIk9yd5bJIvTnJNkv+lqm5srb1t3IUCAAA8GquN9PxCa+3dy7S/O8mRqnpMki8YfVkAAACjsdo1PR9e6YWq+oLW2qdaa/eOuCYAAICRWS30vHXxSVXded5rR0deDQAAwIitFnpqyfMnXeA1AACAqbTaNT1thefLbbNGR0/M5fCxUzl9Zj67ZmdycP+eHNi7e9JlAQBAl1YLPU+pqhdlYVRn8XmG7Z1jraxTR0/M5dCRk5k/ey5JMndmPoeOnEwSwQcAAMZgteltv57kCUkev+T54vZLx1tanw4fO/VQ4Fk0f/ZcDh87NaGKAACgbxcc6Wmt/exGFbJVnD4zv652AADg4lxwpKeq/sequmJ4XlX18qr626p6V1Xt3ZgS+7JrdmZd7QAAwMVZbXrbC5N8aHj+giRfnuTpSV6U5N+Or6x+Hdy/JzM7tj2ibWbHthzcv2dCFQEAQN9WCz0PttbODs+/OclvtNb+prX2+0keN97S+nRg7+7cdO2V2T07k0qye3YmN117pUUMAABgTFZbve3TVXVJko8neU6Sn1/ymvlYj9KBvbuFHAAA2CCrhZ6fTnI8ybYkb2itvSdJquqfJ/ngmGsDAAC4aKut3vbGqvrCJE9orX18yUvvSPKdY60MAABgBFZbve2fJHnyYuCpqu+tqtuT3JzkMRtQHwAAwEVZbSGDX0vyqSSpqq/KQtj5jSR/m+SW8ZYGAABw8Va7pmdba+1jw/PvTHJLa+31SV5fVfeMtzQAAICLt9pIz7aqWgxGz0ly15LXVgtMAAAAE7dacHl1kj+oqr9OMp/kD5Okqr4oC1PcAAAAptpqq7f9fFXdmeSSJL/XWmvDS5+V5EfGXRwAAMDFumDoqarHt9b+5Pz21tp/Om+fT46jOAAAgIu12jU9t1fVL1TVV1XV4xYbq+rpVXV9VR1Lcs14SwQAAHj0Vpve9pyq+sYkP5Dk6qp6YpIHk5xK8qYk17XW/mr8ZQIAADw6q67A1lp7c5I3b0AtAAAAI7fa9DYAAIBNzb12NrGjJ+Zy+NipnD4zn12zMzm4f08O7N096bIAAGCqCD2b1NETczl05GTmz55Lksydmc+hIyeTRPABAIAl1jS9rar+QVV99vD8q6vqf66q2fGWxoUcPnbqocCzaP7suRw+dmpCFQEAwHRa6zU9r09yrqq+KMnLklye5FVjq4pVnT4zv652AADYqtYaej7dWnswybcm+eXW2o8luWR8ZbGaXbMz62oHAICtaq2h52xVvSDJdUneOLTtGE9JrMXB/Xsys2PbI9pmdmzLwf17JlQRAABMp7WGnu9L8s+S/Hxr7S+q6vIkv3mhN1TVY6vqT6vqnVX1nqr62aH98qp6e1W9v6peW1WPubgfYWs6sHd3brr2yuyenUkl2T07k5uuvdIiBgAAcJ5qra3vDVVPTPK01tq7VtmvkjyutfbJqtqR5I+SvDDJi5Icaa29pqp+Nck7W2svudCx9u3b144fP76uOgEAgK2jqu5ure1b7rW1rt721qr63Kp6UpJ3JnlFVf3ihd7TFnxy2Nwx/GlJnp3ktqH91iQH1lIDAADAo7HW6W2f11r7uyTXJnlFa+0fJ/na1d5UVduq6p4k9ye5I8kHkpwZFkVIkvuSmI8FAACMzVpDz/aquiTJd+ThhQxW1Vo711q7KsmlSZ6Z5EuW222591bVDVV1vKqOP/DAA2v9SAAAgEdYa+j510mOJflAa+0dVfX0JO9f64e01s4keWuSZyWZrartw0uXJjm9wntuaa3ta63t27lz51o/CgAA4BHWFHpaa/93a+3LWmv/atj+YGvt2y70nqraWVWzw/OZLEyHe1+StyT59mG365Lc/miLBwAAWM1aFzK4tKp+u6rur6qPVtXrq+rSVd52SZK3VNW7krwjyR2ttTcm+ckkL6qqe5N8fpKXXcwPAAAAcCHbV98lSfKKJK9K8rxh+7uHtq9b6Q3DktZ7l2n/YBau7wEAABi7tV7Ts7O19orW2oPDn1cmcaENAAAw9dYaev66qr57WIJ6W1V9d5K/GWdhAAAAo7DW0PP9WViu+q+SfCQLCxF837iKAgAAGJW1rt724dbat7TWdrbWntJaO5CFG5UCAABMtbWO9CznRSOrAgAAYEwuJvTUyKoAAAAYk4sJPW1kVQAAAIzJBe/TU1WfyPLhppLMjKUiAACAEbpg6GmtPWGjCgEAABiHi5neBgAAMPWEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXtk+6ACbv6Im5HD52KqfPzGfX7EwO7t+TA3t3T7osAAAYCaFnizt6Yi6HjpzM/NlzSZK5M/M5dORkkgg+AAB0wfS2Le7wsVMPBZ5F82fP5fCxUxOqCAAARkvo2eJOn5lfVzsAAGw2Qs8Wt2t2Zl3tAACw2Qg9W9zB/Xsys2PbI9pmdmzLwf17JlQRAACMloUMtrjFxQqs3gYAQK+EHnJg724hBwCAbpneBgAAdE3oAQAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrQg8AANA1oQcAAOia0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdE3oAQAAuib0AAAAXds+6QLox9ETczl87FROn5nPrtmZHNy/Jwf27p50WQAAbHFCDyNx9MRcDh05mfmz55Ikc2fmc+jIySQRfAAAmCjT2xiJw8dOPRR4Fs2fPZfDx05NqCIAAFgg9DASp8/Mr6sdAAA2itDDSOyanVlXOwAAbBShh5E4uH9PZnZse0TbzI5tObh/z4QqAgCABRYyYCQWFyuwehsAANNG6GFkDuzdLeQAADB1TG8DAAC6JvQAAABdM70NNqGjJ+ZcPwUAsEZCD2wyR0/M5dCRkw/dDHbuzHwOHTmZJIIPAMAyTG+DTebwsVMPBZ5F82fP5fCxUxOqCABgugk9sMmcPjO/rnYAgK1ubKGnqp5WVW+pqvdV1Xuq6oVD+5Oq6o6qev/w+MRx1QA92jU7s652AICtbpwjPQ8m+fHW2pckeVaSH6qqZyS5McmdrbUrktw5bANrdHD/nszs2PaItpkd23Jw/54JVQQAMN3GFnpaax9prf3Z8PwTSd6XZHeS5ya5ddjt1iQHxlUD9OjA3t256dors3t2JpVk9+xMbrr2SosYAACsYENWb6uqy5LsTfL2JE9trX0kWQhGVfWUjagBenJg724hBwBgjca+kEFVPT7J65P8aGvt79bxvhuq6nhVHX/ggQfGVyAAANC1sYaeqtqRhcDzW621I0PzR6vqkuH1S5Lcv9x7W2u3tNb2tdb27dy5c5xlAgAAHRvn6m2V5GVJ3tda+8UlL70hyXXD8+uS3D6uGgAAAMZ5Tc/VSb4nycmqumdo+6kkNyd5XVVdn+TDSZ43xhrYhI6emMvhY6dy+sx8ds3O5OD+Pa5fAQDgURtb6Gmt/VGSWuHl54zrc9ncjp6Yy6EjJzN/9lySZO7MfA4dOZkkgg8AAI/K2BcygPU4fOzUQ4Fn0fzZczl87NSEKgIAYLPbkCWrYa1On5lfV/tqTJUDAMBID1Nl1+zMutovZHGq3NyZ+bQ8PFXu6Im5i6wSAIDNROhhqhzcvyczO7Y9om1mx7Yc3L9n3ccyVQ4AgMT0NqbM4tSzUUxJG/VUOQAANiehh6lzYO/ukVx3s2t2JnPLBJxHM1UOAIDNy/Q2ujXKqXIAAGxeRnro1iinygEAsHkJPXRtVFPlAADYvExvAwAAuib0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXtk+6ANgMjp6Yy+Fjp3L6zHx2zc7k4P49ObB396TLAgBgDYQeWMXRE3M5dORk5s+eS5LMnZnPoSMnk0TwAQDYBExvg1UcPnbqocCzaP7suRw+dmpCFQEAsB5CD6zi9Jn5dbUDADBdhB5Yxa7ZmXW1AwAwXYQeWMXB/Xsys2PbI9pmdmzLwf17JlQRAADrYSEDWMXiYgVWbwMA2JyEHliDA3t3CzkAAJuU6W0AAEDXhB4AAKBrQg8AANA1oQcAAOiahQxgAx09MWcVOACADSb0wAY5emIuh46czPzZc0mSuTPzOXTkZJIIPgAAY2R6G2yQw8dOPRR4Fs2fPZfDx05NqCIAgK1B6IENcvrM/LraAQAYDaEHNsiu2Zl1tQMAMBpCD2yQg/v3ZGbHtke0zezYloP790yoIgCArcFCBrBBFhcr6HX1NivTAQDTSuiBDXRg7+4ug4CV6QCAaWZ6G3DRrEwHAEwzoQe4aFamAwCmmdADXDQr0wEA00zoAS6alekAgGlmIQPgovW+Mh0AsLkJPcBI9LoyHQCw+ZneBgAAdE3oAQAAuib0AAAAXXNND2xhR0/MWXwAAOie0ANb1NETczl05GTmz55Lksydmc+hIyeTRPABALpiehtsUYePnXoo8CyaP3suh4+dmlBFAADjIfTAFnX6zPy62gEANiuhB7aoXbMz62oHANishB7Yog7u35OZHdse0TazY1sO7t8zoYoAAMbDQgawRS0uVmD1NgCgd0IPbGEH9u7uNuRYjhsAWCT0AN2xHDcAsJRreoDuWI4bAFhK6AG6YzluAGApoQfojuW4AYClhB6gO5bjBgCWspAB0B3LcQMASwk9wFQZ1VLTPS/HDQCsj9ADTA1LTQMA4+CaHmBqWGoaABgHoQeYGpaaBgDGQegBpoalpgGAcRB6gKlhqWkAYBwsZABMDUtNAwDjIPQAU8VS0wDAqJneBgAAdE3oAQAAuib0AAAAXRN6AACAro0t9FTVy6vq/qp695K2J1XVHVX1/uHxieP6fAAAgGS8Iz2vTHLNeW03JrmztXZFkjuHbQAAgLEZW+hprb0tycfOa35ukluH57cmOTCuzwcAAEg2/pqep7bWPpIkw+NTNvjzAQCALWZqFzKoqhuq6nhVHX/ggQcmXQ4AALBJbXTo+WhVXZIkw+P9K+3YWrultbavtbZv586dG1YgAADQl40OPW9Ict3w/Lokt2/w5wMAAFvMOJesfnWS/5hkT1XdV1XXJ7k5yddV1fuTfN2wDQAAMDbbx3Xg1toLVnjpOeP6TAAAgPNN7UIGAAAAoyD0AAAAXRN6AACArgk9AABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABd2z7pAgCm2dETczl87FROn5nPrtmZHNy/Jwf27p50WQDAOgg9ACs4emIuh46czPzZc0mSuTPzOXTkZJIIPgCwiZjeBrCCw8dOPRR4Fs2fPZfDx05NqCIA4NEQegBWcPrM/LraAYDpZHobwAp2zc5kbpmAs2t2ZgLVPMx1RgCwPkZ6AFZwcP+ezOzY9oi2mR3bcnD/nglV9PB1RnNn5tPy8HVGR0/MTawmAJh2Qg/ACg7s3Z2brr0yu2dnUkl2z87kpmuvnOioiuuMAGD9TG8DuIADe3dP1dQx1xkBwPoZ6QHYRFa6nmjS1xkBwDQTegA2kWm8zggApp3pbQCbyOJUO6u3AcDaCT0Am8y0XWcEANNO6AHYAO6tAwCTI/QAjNnivXUWl5pevLdOEsFnixB6ASbLQgYAY+beOlubG8oCTJ7QAzBm7q2ztQm9AJNnehvAmO2ancncMgGnl3vrmLp1YUIvwOQZ6QEYs57vrWPq1urcUBZg8oQegDE7sHd3brr2yuyenUkl2T07k5uuvXLioyFHT8zl6pvvyuU3vilX33zXowoqpm6trufQC7BZmN4GsAGm7d46o1pRztSt1bmhLMDkCT0AW9CFRmjW82W89+uVRmXaQi/AVmN6G8AWNKoRGlO3ANgMhB6ALWhUF9dP6/VKALCU6W0AW9DB/XsecU1P8uhHaEzdAmDaCT0AW9A0Xlzvfj8AjIvQA7BFTdMIzahWkwOA5Qg9AEzcqFaTW2TUCIClhB4AJm6U9/sxasQoCM7QF6u3ATBxo1pNLrnwqNF6HT0xl6tvviuX3/imXH3zXTl6Ym7dx2DzWQzOc2fm0/JwcPb3D5uX0APAxI3yfj+jGjWaxi++0xjCprGmizXK4AxMB6EHgIkb5f1+RjVqNG1ffKc1hE1bTaMwyumWwHRwTQ8AU2FUq8mN6h5E0/bFd9SLPfRa0yjsmp3J3DJ/z49muiUwHYz0ANCVUY0ajfI6o1GYthB2oc/e7CMio5xuOUo9TiWEjWKkB4DujGLUaFQjRqMyytGHUa1MNo01jcK03rzXqoQbZ5rOR0ZD6AGAZUzbF99RhbBRfnmexppGZZpu3pv0O5VwGk3j+cjFE3oAYAXT9MV3VCFslF+ep7GmXk3jVMJeR0Ocj30SegBgkxhFCBv1l+dprKlH07a4Qs+jIc7HPlnIAAC2kGlboOFCn/1orw3q8WL/aVtcYdqWdB+lafxvhIsn9ADAFjJtX56T0dU0jfcNGlUIG+W9rEah59GQafxvhItnehsAbCHTtkDDKGuatmsxRj0FbFTXmI3iWpxpm243StP43wgXr1prk65hVfv27WvHjx+fdBkAwBS7/MY3ZblvNZXkL27+po0uJ1fffNeywWD37Ez++MZnb3g9yWcGsWRhFGO9o0ajOs4o9bqwAmtXVXe31vYt95rpbQBAF6btWoxpnAI2qmtxpm263TRObWS6mN4GAHSh5xvKjsoog9g0Lek+bVMbmT5GegCALkzb6MM0XhA/baNhyWgWe5jGUTWmi5EeAKAb0zT6MI0XxE/baNioFnuYxlG1ZHTXGU3bcTYjoQcAYEymKYQl0xfERjUtbdrCXDK6QDdtx9mshB4AgC1kmoLYqKalTVuYW6xlFIFu2o6zWQk9AABMxCinpU1TmEtGF+im7TiLNttUOQsZAAAwEdO42MOojGrRiGk7TrI5lwgXegAAmIhpW3FvlEYV6KbtOMno7ve0kUxvAwBgYqZtWtqojOo6o2k7TrI5lwiv1tqka1jVvn372vHjxyddBgAAbHlX33zXstdi7Z6dyR/f+OwJVLSgqu5ure1b7jXT2wAAgDXbjNdimd4GAACs2TQuEb4aoQcAAFiXzXYtlultAABA14QeAACga0IPAADQNaEHAADomtADAAB0TegBAAC6JvQAAABdE3oAAICuCT0AAEDXhB4AAKBrEwk9VXVNVZ2qqnur6sZJ1AAAAGwNGx56qmpbkl9J8g1JnpHkBVX1jI2uAwAA2BomMdLzzCT3ttY+2Fr7VJLXJHnuBOoAAEDlpUMAAA11SURBVAC2gEmEnt1J/nLJ9n1DGwAAwMhNIvTUMm3tM3aquqGqjlfV8QceeGADygIAAHo0idBzX5KnLdm+NMnp83dqrd3SWtvXWtu3c+fODSsOAADoyyRCzzuSXFFVl1fVY5I8P8kbJlAHAACwBWzf6A9srT1YVT+c5FiSbUle3lp7z0bXAQAAbA0bHnqSpLX25iRvnsRnAwAAW8tEbk4KAACwUaq1z1g4bepU1QNJ/vNFHubJSf56BOWwOn29cfT1xtHXG0dfbxx9vXH09cbR1xtrmvr7C1try66AtilCzyhU1fHW2r5J17EV6OuNo683jr7eOPp64+jrjaOvN46+3libpb9NbwMAALom9AAAAF3bSqHnlkkXsIXo642jrzeOvt44+nrj6OuNo683jr7eWJuiv7fMNT0AAMDWtJVGegAAgC1oS4Seqrqmqk5V1b1VdeOk6+lNVX2oqk5W1T1VdXxoe1JV3VFV7x8enzjpOjejqnp5Vd1fVe9e0rZs39aCfzuc5++qqq+YXOWbzwp9/TNVNTec2/dU1Tcuee3Q0Nenqmr/ZKrenKrqaVX1lqp6X1W9p6peOLQ7t0fsAn3t3B6xqnpsVf1pVb1z6OufHdovr6q3D+f1a6vqMUP7Zw/b9w6vXzbJ+jeTC/T1K6vqL5ac11cN7X6HXKSq2lZVJ6rqjcP2pjuvuw89VbUtya8k+YYkz0jygqp6xmSr6tLXtNauWrJk4Y1J7mytXZHkzmGb9XtlkmvOa1upb78hyRXDnxuSvGSDauzFK/OZfZ0kvzSc21e11t6cJMPvkOcn+UfDe/798LuGtXkwyY+31r4kybOS/NDQp87t0VuprxPn9qj9fZJnt9a+PMlVSa6pqmcleXEW+vqKJB9Pcv2w//VJPt5a+6IkvzTsx9qs1NdJcnDJeX3P0OZ3yMV7YZL3LdnedOd196EnyTOT3Nta+2Br7VNJXpPkuROuaSt4bpJbh+e3JjkwwVo2rdba25J87Lzmlfr2uUl+oy34kySzVXXJxlS6+a3Q1yt5bpLXtNb+vrX2F0nuzcLvGtagtfaR1tqfDc8/kYV/SHfHuT1yF+jrlTi3H6Xh/PzksLlj+NOSPDvJbUP7+ef14vl+W5LnVFVtULmb2gX6eiV+h1yEqro0yTcleemwXdmE5/VWCD27k/zlku37cuFf+KxfS/J7VXV3Vd0wtD21tfaRZOEf3SRPmVh1/Vmpb53r4/HDw3SIl9fD0zT19YgMUx/2Jnl7nNtjdV5fJ87tkRumAN2T5P4kdyT5QJIzrbUHh12W9udDfT28/rdJPn9jK968zu/r1trief3zw3n9S1X12UOb8/ri/HKSn0jy6WH787MJz+utEHqWS5eWrButq1trX5GF4eMfqqqvmnRBW5RzffRekuQfZGH6xEeS/MLQrq9HoKoen+T1SX60tfZ3F9p1mTb9vQ7L9LVzewxaa+daa1cluTQLI2Rfstxuw6O+vgjn93VVfWmSQ0n+YZJ/kuRJSX5y2F1fP0pV9c1J7m+t3b20eZldp/683gqh574kT1uyfWmS0xOqpUuttdPD4/1JfjsLv+g/ujh0PDzeP7kKu7NS3zrXR6y19tHhH9ZPJ/n1PDzNR19fpKrakYUv4b/VWjsyNDu3x2C5vnZuj1dr7UySt2bhOqrZqto+vLS0Px/q6+H1z8vap9gyWNLX1wzTOVtr7e+TvCLO61G4Osm3VNWHsnCJyLOzMPKz6c7rrRB63pHkimGVicdk4QLNN0y4pm5U1eOq6gmLz5N8fZJ3Z6GPrxt2uy7J7ZOpsEsr9e0bknzvsErNs5L87eJUIR6d8+Z8f2sWzu1koa+fP6xSc3kWLo79042ub7Ma5ne/LMn7Wmu/uOQl5/aIrdTXzu3Rq6qdVTU7PJ9J8rVZuIbqLUm+fdjt/PN68Xz/9iR3NTdPXJMV+vrPl/xPk8rCNSZLz2u/Qx6F1tqh1tqlrbXLsvAd+q7W2ndlE57X21ffZXNrrT1YVT+c5FiSbUle3lp7z4TL6slTk/z2cI3a9iSvaq39blW9I8nrqur6JB9O8rwJ1rhpVdWrk3x1kidX1X1J/vckN2f5vn1zkm/MwoXH/zXJ9214wZvYCn391cOSpy3Jh5L8QJK01t5TVa9L8t4srI71Q621c5Ooe5O6Osn3JDk5zMlPkp+Kc3scVurrFzi3R+6SJLcOq919VpLXtdbeWFXvTfKaqvq5JCeyEEIzPP6Hqro3C/8n/PmTKHqTWqmv76qqnVmYYnVPkh8c9vc7ZPR+MpvsvK4pCV8AAABjsRWmtwEAAFuY0AMAAHRN6AEAALom9AAAAF0TegAAgK4JPQBjUlWfX1X3DH/+qqrmlmw/Zo3HeEVV7Vllnx+qqu8aTdXLHv/aqvqH4zr+8BmfVVVvqarHV9X2qjq3pK/uqaqDI/ysL1qyfPOG24j+HD7nf6uq7zyv7Xur6mRVvauq/riqrhzaH1tVfzAsAQzQne7v0wMwKa21v0lyVZJU1c8k+WRr7d8s3We4iV611j69wjFWvZ9Ea+1XLr7aC7o2yaeT/PkYP+NfJDneWvvkcBfvT7TWrhrj503SRvRnknxdkvPPjQ8k+crW2pmq+hdJfjXJ1a21/6+q3paFmwm+dsx1AWw4Iz0AG2wYaXh3Vf1qkj9LcklV3VJVx6vqPVX100v2/aOqumoY/ThTVTdX1Tur6j9W1VOGfX6uqn50yf43V9WfVtWpqvpvh/bHVdXrh/e+eviszwgVVXW4qt47jAS8uKq+Mgs39fulYcTlsqq6oqqOVdXdVfW2qvri4b2/WVUvqao/rKr/VFXfMLRfWVXvGN7/rqp6+jLd8l15+I7eF+q7+5b8fG9fPFZVXT6MFL2rqu6oqkuH9v+mqm4f2t9ZVf90ONT2qnrZ0N+/U1WPHfb/seHnf2dV/eaa/kIvXO9E+rOGu9W31j62tL219settTPD5p8kuXTJy0ez8PcA0B0jPQCT8Ywk39da+8EkqaobW2sfG0Y53lJVt7XW3nveez4vyR+01m6sql9M8v1Jbl7m2NVae2ZVfUuSn05yTZIfSfJXrbVvq6ovz0LYeuSbqp6ahS/k/6i11qpqdhgReHOS21prR4f93pLkf2itfaCqrk7y75J8/XCYpyX550muSPL7VfVFSf6nJP+mtfbaqvrsLNwt/XxXJ/nvl2w/oR45Be3nWmu3Dc8/Pvx835/kF5McSPLvk7y0tfZbVXVDkl/OwqjFryS5o7X274a+/ZwkT0myJ8kLWmsnq+rIcIzXJPmJJF/YWvvUYnA4r4+ekeRVy9SfLIygfGJK+vPrk/z+CnUuuj7J7yzZfmeSZ63yHoBNSegBmIwPtNbesWT7BVV1fRZ+L+/KQig6P/TMt9YWv6TeneQrVzj2kSX7XDY8/++SvDhJWmvvrKr3LPO+j2Vh2tWvV9Wbkrzx/B2GIPCsJK+veui79tJ/S143TNU7VVV/mYUv6/9vkv+1qr4wyZHW2r3LfPYTWmv/dcn2haa3vXp4/K08HPr+aZJvHp7/RpL/Y3j+1UmenySttQeT/N0wQnZva+3ksM/SfnpPkt+sqtuzMPLxCEMQXeu0u0n25zVJXrJSYVX1tUm+JwvnxeLP9mBVtaqaaa3Nr/FnBNgUTG8DmIz/svikqq5I8sIkz26tfVmS303y2GXe86klz89l5f9x9ffL7LPcaMAjtNbOJtmXhS/735bkTcvsVkn+urV21ZI/X7r0MJ952PYfknzrUNcdVfVVyxx32WuaVip1HfuutP/fL3m+tJ/2Z+E6l2cmOV7nXdhfVc+oRy6wsPTPEx7xoZPtz3+chTD3mR+4MK3x15I8t7X28fNefkwe2TcAXRB6ACbvc5N8IgujEJdk4Yv3qP1Rku9IFq4JycJI0iMMX9o/t7X2xiQ/lmTv8NInkjwhSYYvyR+pqm8d3vNZw3S5Rc+rBV+chalZ76+qp7fW7m2t/Z9Z+OL/ZcvUd29VXbbGn2VxRbIXJPnj4fmfLP58Sb47yduG529JsjiFcFtVfe5KBx0CzqWttbuSHEyyMwvT4R7SWnvveQFl6Z9PnHe8ifTn8P6Tyy2OMfTxbUn+5fkjRMN0vLmVFtUA2MyEHoDJ+7MsTGV7d5Jfz8Nf5Efp/0qyu6releTHh8/62/P2+bwkb6qqdya5K8mLhvZXJ/mpxQvvszBd7AeH/d6Th6eVJcm9WQgc/0+SG1prn0ryL4cFA+5J8vQkyy0Q8KYsTEVb9ITzRlF+fslrn1NVf5rkXw0/S5L8cJIbhp/vO7MQMhbb91fVySTHk1xoqejtSV41HOPPkrz4/CCzTpPqz2/Iwmjhcn4myZOS/Nrw+W9f8trXZPnRKIBNr1pb7ywBADab4SL+7cPSxFck+b0kVwzXuYzqM34zSy7QX+d7L83CQgTXrLLffUm+dMkKZN16tP1ZVXcl+c7W2gPrfN/tSX58hWuEADY1CxkAbA2PT3LnEH4qyQ+MMvBcrNbafVX1yqp6fGvtk5OuZzNrrT17ve8ZVoG7TeABemWkBwAA6JpregAAgK4JPQAAQNeEHgAAoGtCDwAA0DWhBwAA6JrQAwAAdO3/B75UqhpfTB2UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# manually set the parameters of the figure to and appropriate size\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "loss_values = [ev['loss'] for ev in evaluations]\n",
    "training_steps = [ev['global_step'] for ev in evaluations]\n",
    "\n",
    "plt.scatter(x=training_steps, y=loss_values)\n",
    "plt.xlabel('Training steps (Epochs = steps / 2)')\n",
    "plt.ylabel('Loss (SSE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "The Explained Variance: -2.59\n",
      "The Mean Absolute Error: 1.19 \n",
      "The Median Absolute Error: 1.00 \n"
     ]
    }
   ],
   "source": [
    "pred = regressor.predict(input_fn=wx_input_fn(X_test,\n",
    "                                              num_epochs=1,\n",
    "                                              shuffle=False))\n",
    "predictions = np.array([p['predictions'][0] for p in pred])\n",
    "\n",
    "print(\"The Explained Variance: %.2f\" % explained_variance_score(\n",
    "                                            y_test, predictions))  \n",
    "print(\"The Mean Absolute Error: %.2f \" % mean_absolute_error(\n",
    "                                            y_test, predictions))  \n",
    "print(\"The Median Absolute Error: %.2f \" % median_absolute_error(\n",
    "                                            y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
